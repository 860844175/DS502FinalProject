Lasso_ori_lambda[i] = Lasso.ori.lambda
Lasso.ori.Pred <- predict(Lasso.ori.Fit, s= Lasso.ori.lambda, newx = X_test)
Lasso.ori.Pred1 <- predict(Lasso.ori.Fit, s= Lasso.ori.lambda, newx = X_train)
Lasso.ori.coef = predict(Lasso.ori.Fit, s = Lasso.ori.lambda, type="coefficients")
Lasso_ori_coef = Lasso_ori_coef + Lasso.ori.coef
Lasso_ori_train[i] = mean(-0.05<=(((Lasso.ori.Pred1)-(y_train))/(y_train))&(((Lasso.ori.Pred1)-(y_train))/(y_train)) <=0.2)
Lasso_ori_accuracy[i] = mean(-0.05<=(((Lasso.ori.Pred)-(y_test))/(y_test))&(((Lasso.ori.Pred)-(y_test))/(y_test)) <=0.2)
Lasso_ori_R2[i] = R2(Lasso.ori.Pred,(y_test))
Lasso_ori_RMSE[i]= RMSE(Lasso.ori.Pred,(y_test))
Lasso_ori_MAE[i] = MAE(Lasso.ori.Pred,(y_test))
}
Lasso_ori_aver_lambda = mean(Lasso_ori_lambda)
Lasso_ori_aver_accuracy = mean(Lasso_ori_accuracy)
Lasso_ori_aver_RMSE = mean(Lasso_ori_RMSE)
Lasso_ori_aver_R2 = mean(Lasso_ori_R2)
Lasso_ori_aver_MAE = mean(Lasso_ori_MAE)
Lasso_ori_aver_train = mean(Lasso_ori_train)
n = length(Lasso.ori.coef)
Lasso_ori_aver_coef = (Lasso_ori_coef/5)[1:n,]
k = 5
Lasso_log_accuracy= rep(0,k)
Lasso_log_lambda = rep(0,k)
Lasso_log_R2 = rep(0,k)
Lasso_log_MAE = rep(0,k)
Lasso_log_RMSE = rep(0,k)
Lasso_log_coef = 0
Lasso_log_train = rep(0,k)
for ( i in 1:k){
set.seed(60+i)
sample = sample(nrow(train_log),nrow(train_log),replace = T)
log_train = train_log[sample,]
train = sample(nrow(log_train),0.7*nrow(log_train))
training_dataset = log_train[train,]
validation_dataset = log_train[-train,]
X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
y_train = training_dataset$SalePrice
y_test = validation_dataset$SalePrice
set.seed(150+i)
grid=10^seq(10,-2, length =100)
Lasso.log.Alpha=1
Lasso.log.Fit = glmnet(X_train, y_train, alpha=Lasso.log.Alpha, lambda=grid)
#Lasso.log.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.log.Alpha,nfolds = 10,type.measure = 'deviance')
Lasso.log.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.log.Alpha,lambda = grid)
Lasso.log.lambda = Lasso.log.Fitcv$lambda.min
Lasso_log_lambda[i] = Lasso.log.lambda
Lasso.log.Pred <- predict(Lasso.log.Fit, s= Lasso.log.lambda, newx = X_test)
Lasso.log.Pred = exp(Lasso.log.Pred)
Lasso.log.Pred1 <- predict(Lasso.log.Fit, s= Lasso.log.lambda, newx = X_train)
Lasso.log.Pred1 = exp(Lasso.log.Pred1)
Lasso.log.coef = predict(Lasso.log.Fit, s = Lasso.log.lambda, type="coefficients")
Lasso_log_coef = Lasso_log_coef + Lasso.log.coef
Lasso_log_train[i] = mean(-0.05<=(((Lasso.log.Pred1)-exp(y_train))/exp(y_train))&(((Lasso.log.Pred1)-exp(y_train))/exp(y_train)) <=0.2)
Lasso_log_accuracy[i] = mean(-0.05<=(((Lasso.log.Pred)-exp(y_test))/exp(y_test))&(((Lasso.log.Pred)-exp(y_test))/exp(y_test)) <=0.2)
Lasso_log_R2[i] = R2(Lasso.log.Pred,exp(y_test))
Lasso_log_RMSE[i]= RMSE(Lasso.log.Pred,exp(y_test))
Lasso_log_MAE[i] = MAE(Lasso.log.Pred,exp(y_test))
}
n = length(Lasso_log_coef)
Lasso_log_aver_coef = (Lasso_log_coef/5)[1:n,]
Lasso_log_aver_lambda = mean(Lasso_log_lambda)
Lasso_log_aver_accuracy = mean(Lasso_log_accuracy)
Lasso_log_aver_RMSE = mean(Lasso_log_RMSE)
Lasso_log_aver_R2 = mean(Lasso_log_R2)
Lasso_log_aver_MAE = mean(Lasso_log_MAE)
Lasso_log_aver_train = mean(Lasso_log_train)
# sqrt transformation
#sqrt
Lasso_sqrt_accuracy= rep(0,k)
Lasso_sqrt_lambda = rep(0,k)
Lasso_sqrt_R2 = rep(0,k)
Lasso_sqrt_MAE = rep(0,k)
Lasso_sqrt_RMSE = rep(0,k)
Lasso_sqrt_coef = 0
Lasso_sqrt_train = rep(0,k)
for ( i in 1:k){
set.seed(100+i)
sample = sample(nrow(train_sqrt),nrow(train_sqrt),replace = T)
sqrt_train = train_sqrt[sample,]
train = sample(nrow(sqrt_train),0.7*nrow(sqrt_train))
training_dataset = sqrt_train[train,]
validation_dataset = sqrt_train[-train,]
X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
y_train = training_dataset$SalePrice
y_test = validation_dataset$SalePrice
set.seed(1370+i)
grid=10^seq(10,-2, length =100)
Lasso.sqrt.Alpha=1
Lasso.sqrt.Fit = glmnet(X_train, y_train, alpha=Lasso.sqrt.Alpha, lambda=grid)
Lasso.sqrt.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.sqrt.Alpha,nfolds = 10,type.measure = 'deviance')
Lasso.sqrt.lambda = Lasso.sqrt.Fitcv$lambda.min
Lasso_sqrt_lambda[i] = Lasso.sqrt.lambda
Lasso.sqrt.Pred = predict(Lasso.sqrt.Fit, s= Lasso.sqrt.lambda, newx = X_test)
Lasso.sqrt.Pred = Lasso.sqrt.Pred^4
Lasso.sqrt.Pred1 = predict(Lasso.sqrt.Fit, s= Lasso.sqrt.lambda, newx = X_train)
Lasso.sqrt.Pred1 = Lasso.sqrt.Pred1^4
Lasso.sqrt.coef = predict(Lasso.sqrt.Fit, s = Lasso.sqrt.lambda, type="coefficients")
Lasso_sqrt_coef = Lasso_sqrt_coef + Lasso.sqrt.coef
Lasso_sqrt_train[i] = mean(-0.05<=(((Lasso.sqrt.Pred1)-(y_train)^4)/(y_train)^4)&(((Lasso.sqrt.Pred1)-(y_train)^4)/(y_train)^4) <=0.2)
Lasso_sqrt_accuracy[i] = mean(-0.05<=(((Lasso.sqrt.Pred)-(y_test)^4)/(y_test)^4)&(((Lasso.sqrt.Pred)-(y_test)^4)/(y_test)^4) <=0.2)
Lasso_sqrt_R2[i] = R2(Lasso.sqrt.Pred,(y_test)^4)
Lasso_sqrt_RMSE[i]= RMSE(Lasso.sqrt.Pred,(y_test)^4)
Lasso_sqrt_MAE[i] = MAE(Lasso.sqrt.Pred,(y_test)^4)
}
n = length(Lasso_sqrt_coef)
Lasso_sqrt_aver_coef = (Lasso_sqrt_coef/5)[1:n,]
Lasso_sqrt_aver_lambda = mean(Lasso_sqrt_lambda)
Lasso_sqrt_aver_accuracy = mean(Lasso_sqrt_accuracy)
Lasso_sqrt_aver_RMSE = mean(Lasso_sqrt_RMSE)
Lasso_sqrt_aver_R2 = mean(Lasso_sqrt_R2)
Lasso_sqrt_aver_MAE = mean(Lasso_sqrt_MAE)
Lasso_sqrt_aver_train = mean(Lasso_sqrt_train)
# lambda of original
Lasso_ori_aver_lambda
# lambda of log transformation
Lasso_log_aver_lambda
# lambda of sqrt transformation
Lasso_sqrt_aver_lambda
#par(mfrow=c(2,2))
# plot(Lasso.ori.Fitcv)
# plot(Lasso.log.Fitcv)
# plot(Lasso.sqrt.Fitcv)
#par(mfrow = c(1,1))
# coefficient chose by Lasso
names(head(sort(Lasso_ori_aver_coef[Lasso_ori_aver_coef!=0][-1],decreasing = TRUE),10))
# coefficient chose by Lasso after log transformation
names(head(sort(Lasso_log_aver_coef[Lasso_log_aver_coef!=0][-1],decreasing = TRUE),10))
# coefficient chose by Lassoafter sqrt transformation
names(head(sort(Lasso_sqrt_aver_coef[Lasso_sqrt_aver_coef!=0][-1],decreasing = TRUE),10))
# original accuracy
printf("Accuracy of Lasso is approximately %.2f%%", Lasso_ori_aver_accuracy*100)
# log accuracy
printf("Accuracy of Lasso with Log Transformation is approximately %.2f%%", Lasso_log_aver_accuracy*100)
# sqrt accuracy
printf("Accuracy of Lasso with Sqrt Transformation is approximately %.2f%%", Lasso_sqrt_aver_accuracy*100)
# accuracy dataframe
Lasso_accuracy_df = data.frame(Lasso = c('training accuracy','testing accuracy'),
ori_accuracy =c(Lasso_ori_aver_train,Lasso_ori_aver_accuracy),
log_accuracy =c(Lasso_log_aver_train,Lasso_log_aver_accuracy),
sqrt_accuracy=c(Lasso_sqrt_aver_train,Lasso_sqrt_aver_accuracy))
x_train_ori.pr = prcomp(x_train_ori)
print(summary(x_train_ori.pr))
plot(c(1:32),x_train_ori.pr$sdev[1:32],xlab="Principal Components",type ="l",ylab="Prop. Variance Explained",main="Prop. Variance Elbow")
# New data list cleansed by PCA size of 868*32, which can take the place of original data.
# Each column is one PC, PC's importance decreases by column number.
# Try CV on number of PC you drop from right to left and know how many PCs are best to use.
newdata = x_train_ori.pr$x[,1:32]
printf("Rows num of training set: %i",nrow(x_train_ori))
printf("Columns num of training set: %i",ncol(x_train_ori))
printf("Rows num of training set after PCA: %i",nrow(newdata))
printf("Columns num of training set after PCA: %i",ncol(newdata))
# PCA portion
train = sample(dim(train_ori)[1],size = dim(train_ori)[1]*0.7)
train.subset = train_ori[train,]
test = train_ori[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
# define a function to generate scree plots
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=1, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=0.9, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
screeplot(x,cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
screeplot(x,type="l",cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
par(mfrow=c(1,1))
}
# x = subset(train.df, select = -c(SalePrice) )
# train.pca <- prcomp(x ,center = TRUE)
# pcaCharts(train.pca)
########################### insert an image  (pca_plot.png) #################################
# validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
# axis(side = 1, at = c(32), cex.axis=0.8)
# abline(v = 32, col = "blue", lty = 5)
# abline(v = 26, col = "dark green", lty = 5)
# axis(side = 1, at = c(26), cex.axis=0.8)
########################### insert another image  (pcr_mse.png) #################################
# start pcr
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.ori = mean((test$SalePrice - pcr_pred[,,32])/test$SalePrice<=0.2 & (test$SalePrice - pcr_pred[,,32])/test$SalePrice>=-0.05)
rsq <- function(x, y) summary(lm(y~x))$r.squared
rsq.ori = rsq(test$SalePrice,pcr_pred[,,32])
rmse <-  function(m, o){sqrt(mean((m - o)^2))}
rmse.ori = rmse(test$SalePrice,pcr_pred[,,32])
train.log = read.csv("./SourceData/train_log.csv")
train_log = train.log
set.seed(667)
train = sample(dim(train_log)[1],size = dim(train_log)[1]*0.7)
train.subset = train_log[train,]
test = train_log[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.log = mean((exp(test$SalePrice) - exp(pcr_pred[,,32]))/exp(test$SalePrice<=0.2) & (exp(test$SalePrice) - exp(pcr_pred[,,32]))/exp(test$SalePrice)>=-0.05)
rsq.log = rsq(test$SalePrice,pcr_pred[,,32])
rmse.log = rmse(exp(test$SalePrice),exp(pcr_pred[,,32]))
train.sqrt = read.csv("./SourceData/train_sqrt.csv")
train_sqrt = train.sqrt
set.seed(233)
train = sample(dim(train_sqrt)[1],size = dim(train_sqrt)[1]*0.7)
train.subset = train_sqrt[train,]
test = train_sqrt[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.sqrt = mean((test$SalePrice^4 - pcr_pred[,,32]^4)/test$SalePrice^4<=0.2 & (test$SalePrice^4 - pcr_pred[,,32]^4)/test$SalePrice^4>=-0.05)
rsq.sqrt = rsq(test$SalePrice,pcr_pred[,,32])
rmse.sqrt = rmse(test$SalePrice^4,pcr_pred[,,32]^4)
x <- data.frame("y" = c("original","log","sqrt"), "Accuracy" = c(accuracy.ori,accuracy.log,accuracy.sqrt), "R2" = c(rsq.ori,rsq.log,rsq.sqrt),"RMSE" = c(rmse.ori,rmse.log,rmse.sqrt))
pander(x)
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_ori))
rfTrain=randomForest(SalePrice~.,data=train_ori, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain)
rfYhat = predict(rfTrain, newdata=x_test_ori)
#table(y_test, rfYhat)
accuracy = mean(((y_test_ori - rfYhat)/y_test_ori<=0.2) & ((y_test_ori - rfYhat)/y_test_ori>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_log))
rfTrain_log=randomForest(SalePrice~.,data=train_log, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_log)
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_sqrt))
rfTrain_sqrt=randomForest(SalePrice~.,data=train_sqrt, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_sqrt)
# PCA portion
train = sample(dim(train_ori)[1],size = dim(train_ori)[1]*0.7)
train.subset = train_ori[train,]
test = train_ori[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
# define a function to generate scree plots
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=1, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=0.9, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
screeplot(x,cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
screeplot(x,type="l",cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
par(mfrow=c(1,1))
}
x = subset(train.df, select = -c(SalePrice) )
train.pca <- prcomp(x ,center = TRUE)
pcaCharts(train.pca)
########################### insert an image  (pca_plot.png) #################################
# validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
# axis(side = 1, at = c(32), cex.axis=0.8)
# abline(v = 32, col = "blue", lty = 5)
# abline(v = 26, col = "dark green", lty = 5)
# axis(side = 1, at = c(26), cex.axis=0.8)
########################### insert another image  (pcr_mse.png) #################################
# PCA portion
train = sample(dim(train_ori)[1],size = dim(train_ori)[1]*0.7)
train.subset = train_ori[train,]
test = train_ori[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
# define a function to generate scree plots
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=1, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=0.9, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
screeplot(x,cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
screeplot(x,type="l",cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
par(mfrow=c(1,1))
}
x = subset(train.df, select = -c(SalePrice) )
train.pca <- prcomp(x ,center = TRUE)
pcaCharts(train.pca)
########################### insert an image  (pca_plot.png) #################################
validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
axis(side = 1, at = c(32), cex.axis=0.8)
abline(v = 32, col = "blue", lty = 5)
abline(v = 26, col = "dark green", lty = 5)
axis(side = 1, at = c(26), cex.axis=0.8)
########################### insert another image  (pcr_mse.png) #################################
rfYhat_log = predict(rfTrain_log, newdata=x_test_log)
#table(y_test, rfYhat)
accuracy = mean(((y_test_log - rfYhat_log)/y_test_log<=0.2) & ((y_test_log - rfYhat_log)/y_test_log>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_ori))
rfTrain_ori=randomForest(SalePrice~.,data=train_ori, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_ori)
rfYhat = predict(rfTrain_ori, newdata=x_test_ori)
#table(y_test, rfYhat)
accuracy = mean(((y_test_ori - rfYhat)/y_test_ori<=0.2) & ((y_test_ori - rfYhat)/y_test_ori>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_log))
rfTrain_log=randomForest(SalePrice~.,data=train_log, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_log)
rfYhat_log = predict(rfTrain_log, newdata=x_test_log)
#table(y_test, rfYhat)
accuracy = mean(((y_test_log - exp(rfYhat_log))/y_test_log<=0.2) & ((y_test_log - exp(rfYhat_log))/y_test_log>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
rfYhat_sqrt = predict(rfTrain_sqrt, newdata=x_test_sqrt)
#table(y_test, rfYhat)
accuracy = mean(((y_test_sqrt - rfYhat_sqrt^4)/y_test_sqrt<=0.2) & ((y_test_sqrt - rfYhat_sqrt^4)/y_test_sqrt>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
test_sqrt = read.csv("./SourceData/test_sqrt.csv")
y_test_sqrt = test_sqrt$SalePrice
x_test_sqrt = subset (test_sqrt, select = -SalePrice)
train_sqrt = read.csv("./SourceData/train_sqrt.csv")
y_train_sqrt = train_sqrt$SalePrice
x_train_sqrt = subset (train_sqrt, select = -SalePrice)
y_train_sqrt = as.numeric(y_train_sqrt)
y_test_sqrt = as.numeric(y_test_sqrt)
summary(y_train_sqrt)
test_log = read.csv("./SourceData/test_log.csv")
y_test_log = test_ori$SalePrice
x_test_log = subset (test_log, select = -SalePrice)
train_log = read.csv("./SourceData/train_log.csv")
y_train_log = train_log$SalePrice
x_train_log = subset (train_log, select = -SalePrice)
y_train_log = as.numeric(y_train_log)
y_test_log = as.numeric(y_test_log)
summary(y_train_log)
test_log = read.csv("./SourceData/test_log.csv")
y_test_log = test_log$SalePrice
x_test_log = subset (test_log, select = -SalePrice)
train_log = read.csv("./SourceData/train_log.csv")
y_train_log = train_log$SalePrice
x_train_log = subset (train_log, select = -SalePrice)
y_train_log = as.numeric(y_train_log)
y_test_log = as.numeric(y_test_log)
summary(y_train_log)
rfYhat_sqrt = predict(rfTrain_sqrt, newdata=x_test_sqrt)
#table(y_test, rfYhat)
accuracy = mean(((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4<=0.2) & ((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
rfYhat_log = predict(rfTrain_log, newdata=x_test_log)
#table(y_test, rfYhat)
accuracy = mean(((y_test_log - exp(rfYhat_log))/y_test_log<=0.2) & ((y_test_log - exp(rfYhat_log))/y_test_log>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
rfYhat_log = predict(rfTrain_log, newdata=x_test_log)
#table(y_test, rfYhat)
accuracy = mean(((exp(y_test_log) - exp(rfYhat_log))/exp(y_test_log)<=0.2) & ((exp(y_test_log) - exp(rfYhat_log))/exp(y_test_log)>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
rfYhat_sqrt = predict(rfTrain_sqrt, newdata=x_test_sqrt)
#table(y_test, rfYhat)
accuracy = mean(((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4<=0.2) & ((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
rfYhat_sqrt = predict(rfTrain_sqrt, newdata=x_test_sqrt)
#table(y_test, rfYhat)
rf_accuracy_sqrt = mean(((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4<=0.2) & ((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_sqrt*100)
rfYhat_log = predict(rfTrain_log, newdata=x_test_log)
#table(y_test, rfYhat)
rf_accuracy_log = mean(((exp(y_test_log) - exp(rfYhat_log))/exp(y_test_log)<=0.2) & ((exp(y_test_log) - exp(rfYhat_log))/exp(y_test_log)>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_log*100)
rfYhat = predict(rfTrain_ori, newdata=x_test_ori)
#table(y_test, rfYhat)
rf_accuracy_ori = mean(((y_test_ori - rfYhat)/y_test_ori<=0.2) & ((y_test_ori - rfYhat)/y_test_ori>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_ori*100)
printf("We have the MSE of the model approximately equal to %.5f", mean((rfYhat-test_ori$SalePrice)^2))
set.seed(123)
# computing model performance metrics
# pander(data.frame( R2 = R2(rfYhat, y_test_ori),
#             RMSE = RMSE(rfYhat, y_test_ori),
#             MAE = MAE(rfYhat, y_test_ori)), title="Cross Validation for Random Forest")
x <- data.frame("y" = c("original","log","sqrt"), "Accuracy" = c(rf_accuracy_ori,rf_accuracy_log,rf_accuracy_sqrt), "R2" = c(R2(rfYhat_ori, y_test_ori),R2(exp(rfYhat_log), exp(y_test_log)),R2(rfYhat_sqrt^4, y_test_sqrt^4)),"RMSE" = c(RMSE(rfYhat_ori, y_test_ori),RMSE(exp(rfYhat_log), exp(y_test_log)),RMSE(rfYhat_sqrt^4, y_test_sqrt^4)))
rfYhat_ori = predict(rfTrain_ori, newdata=x_test_ori)
#table(y_test, rfYhat)
rf_accuracy_ori = mean(((y_test_ori - rfYhat_ori)/y_test_ori<=0.2) & ((y_test_ori - rfYhat_ori)/y_test_ori>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_ori*100)
set.seed(123)
# computing model performance metrics
# pander(data.frame( R2 = R2(rfYhat, y_test_ori),
#             RMSE = RMSE(rfYhat, y_test_ori),
#             MAE = MAE(rfYhat, y_test_ori)), title="Cross Validation for Random Forest")
x <- data.frame("y" = c("original","log","sqrt"), "Accuracy" = c(rf_accuracy_ori,rf_accuracy_log,rf_accuracy_sqrt), "R2" = c(R2(rfYhat_ori, y_test_ori),R2(exp(rfYhat_log), exp(y_test_log)),R2(rfYhat_sqrt^4, y_test_sqrt^4)),"RMSE" = c(RMSE(rfYhat_ori, y_test_ori),RMSE(exp(rfYhat_log), exp(y_test_log)),RMSE(rfYhat_sqrt^4, y_test_sqrt^4)))
pander(x)
set.seed(2)
# Need help with PCA analysis
# pcr.fit=pcr(SalePrice~., data=HousePricing, scale=TRUE, validation ="CV")
train.original = read.csv("./SourceData/train_original.csv")
train_ori = train.original
# PCA portion
train = sample(dim(train_ori)[1],size = dim(train_ori)[1]*0.7)
train.subset = train_ori[train,]
test = train_ori[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
# define a function to generate scree plots
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
# print("proportions of variance:")
# print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=1, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=0.9, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
screeplot(x,cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
screeplot(x,type="l",cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
par(mfrow=c(1,1))
}
x = subset(train.df, select = -c(SalePrice) )
train.pca <- prcomp(x ,center = TRUE)
pcaCharts(train.pca)
########################### insert an image  (pca_plot.png) #################################
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
# summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
axis(side = 1, at = c(32), cex.axis=0.8)
abline(v = 32, col = "blue", lty = 5)
########################### insert another image  (pcr_mse.png) #################################
pcaCharts(train.pca)
set.seed(2)
# Need help with PCA analysis
# pcr.fit=pcr(SalePrice~., data=HousePricing, scale=TRUE, validation ="CV")
train.original = read.csv("./SourceData/train_original.csv")
train_ori = train.original
# PCA portion
train = sample(dim(train_ori)[1],size = dim(train_ori)[1]*0.7)
train.subset = train_ori[train,]
test = train_ori[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
# define a function to generate scree plots
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
# print("proportions of variance:")
# print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=1, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b',cex.lab=0.9, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
screeplot(x,cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
screeplot(x,type="l",cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
par(mfrow=c(1,1))
}
x = subset(train.df, select = -c(SalePrice) )
train.pca <- prcomp(x ,center = TRUE)
pcaCharts(train.pca)
########################### insert an image  (pca_plot.png) #################################
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
# summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
axis(side = 1, at = c(32), cex.axis=0.8)
abline(v = 32, col = "blue", lty = 5)
########################### insert another image  (pcr_mse.png) #################################
validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
axis(side = 1, at = c(19), cex.axis=0.8)
abline(v = 19, col = "blue", lty = 5)
axis(side = 1, at = c(28), cex.axis=0.8)
abline(v = 28, col = "dark green", lty = 5)
# start pcr
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.ori = mean((test$SalePrice - pcr_pred[,,32])/test$SalePrice<=0.2 & (test$SalePrice - pcr_pred[,,32])/test$SalePrice>=-0.05)
rsq <- function(x, y) summary(lm(y~x))$r.squared
rsq.ori = rsq(test$SalePrice,pcr_pred[,,32])
rmse <-  function(m, o){sqrt(mean((m - o)^2))}
rmse.ori = rmse(test$SalePrice,pcr_pred[,,32])
train.log = read.csv("./SourceData/train_log.csv")
train_log = train.log
set.seed(667)
train = sample(dim(train_log)[1],size = dim(train_log)[1]*0.7)
train.subset = train_log[train,]
test = train_log[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.log = mean((exp(test$SalePrice) - exp(pcr_pred[,,32]))/exp(test$SalePrice<=0.2) & (exp(test$SalePrice) - exp(pcr_pred[,,32]))/exp(test$SalePrice)>=-0.05)
rsq.log = rsq(test$SalePrice,pcr_pred[,,32])
rmse.log = rmse(exp(test$SalePrice),exp(pcr_pred[,,32]))
train.sqrt = read.csv("./SourceData/train_sqrt.csv")
train_sqrt = train.sqrt
set.seed(233)
train = sample(dim(train_sqrt)[1],size = dim(train_sqrt)[1]*0.7)
train.subset = train_sqrt[train,]
test = train_sqrt[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.sqrt = mean((test$SalePrice^4 - pcr_pred[,,32]^4)/test$SalePrice^4<=0.2 & (test$SalePrice^4 - pcr_pred[,,32]^4)/test$SalePrice^4>=-0.05)
rsq.sqrt = rsq(test$SalePrice,pcr_pred[,,32])
rmse.sqrt = rmse(test$SalePrice^4,pcr_pred[,,32]^4)
x <- data.frame("y" = c("original","log","sqrt"), "Accuracy" = c(accuracy.ori,accuracy.log,accuracy.sqrt), "R2" = c(rsq.ori,rsq.log,rsq.sqrt),"RMSE" = c(rmse.ori,rmse.log,rmse.sqrt))
pander(x)
