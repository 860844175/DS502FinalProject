---
title: "Homework 1"
author: "Yufei Lin, Jingfeng Xia"
date: "Nov 7 2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
library(pander)
library(knitr)
library(skimr)
library(kableExtra)
library(tinytex)
library(dplyr)
library(purrr)
local({
  hook_inline = knitr::knit_hooks$get('inline')
  knitr::knit_hooks$set(inline = function(x) {
    res = hook_inline(x)
    if (is.numeric(x)) sprintf('$%s$', res) else res
  })
})
```

```{r checkVersion}
# check R version
R.Version()$major
```
```{r libraries, include=FALSE}
library(pander)
library(knitr)
library(skimr)
library(kableExtra)
library(tinytex)
library(dplyr)
library(purrr)
library(pls)
library(randomForest)
library(gam)
library(glmnet)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(caret)
library(mgcv)
library(Metrics)
library(visreg)
```

Variable Name: 
1. HousePricing:1400 dataset
2. train: training data

## Data Processing

### Read in Data

We have chosen to eliminate the ID column from this dataset because ID has nothing to do with our prediction and would mess up our prediction. 

```{r readData}
vault = read.csv("./SourceData/test.csv")
vault = subset(vault, select=-Id)
HousePricing = read.csv("./SourceData/train.csv")
HousePricing = subset(HousePricing,select=-Id)
```

### Pairs of Categories (Iris)

```{r pairsOfCategories}
#pander(summary(HousePricing))
#pairs(HousePricing, main="Pairs plot for the house pricing dataset")
print("Hi")
```

### Feature Engineering

In this section, we convert all missing value based on the following rules:

\begin{enumerate}
\item Categorical: fill in most common
\item Numeric: fill in median/average
\end{enumerate}

Convert all train to HousePricing

```{r fe, include=FALSE}
# remove the irrational data point
ggplot(HousePricing,aes(x=GrLivArea,y=SalePrice))+geom_point()
HousePricing = HousePricing[HousePricing$GrLivArea<4500,]

# find which variables contain NA
NAcol <- which(colSums(is.na(HousePricing)) > 0)
sort(colSums(sapply(HousePricing[NAcol], is.na)), decreasing = TRUE)

# remove NA 
HousePricing$PoolQC[is.na(HousePricing$PoolQC)] = 'None'
quailty = c('None'=0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$PoolQC<-recode(HousePricing$PoolQC,'None'=0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)

HousePricing$MiscFeature[is.na(HousePricing$MiscFeature)] = 'None'
HousePricing$MiscFeature = as.factor(HousePricing$MiscFeature)

HousePricing$Alley[is.na(HousePricing$Alley)] = 'None'
HousePricing$Alley=recode(HousePricing$Alley,'None' = 0,'Pave' = 1,'Grvl' = 2)

HousePricing$Fence[is.na(HousePricing$Fence)] = 'None'
HousePricing$Fence=recode(HousePricing$Fence,'None' = 0,'MnWw' = 1,'GdWo' = 2,'MnPrv' = 3,'GdPrv' = 4)

HousePricing$FireplaceQu[is.na(HousePricing$FireplaceQu)] = 'None'
HousePricing$FireplaceQu=recode(HousePricing$FireplaceQu,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)


HousePricing$LotFrontage[is.na(HousePricing$LotFrontage)]
for (i in 1:nrow(HousePricing)){
  if (is.na(HousePricing$LotFrontage[i])){
    HousePricing$LotFrontage[i] = as.integer(median(HousePricing$LotFrontage[HousePricing$Neighborhood==HousePricing$Neighborhood[i]],na.rm = TRUE))
  }
}


HousePricing$GarageType[is.na(HousePricing$GarageType)] = 'None'
HousePricing$GarageYrBlt[is.na(HousePricing$GarageYrBlt)] <- HousePricing$YearBuilt[is.na(HousePricing$GarageYrBlt)]
HousePricing$GarageFinish[is.na(HousePricing$GarageFinish)] = 'None'
HousePricing$GarageQual[is.na(HousePricing$GarageQual)] = 'None'
HousePricing$GarageCond[is.na(HousePricing$GarageCond)] = 'None'

length(which(is.na(HousePricing$BsmtQual) & is.na(HousePricing$BsmtCond) & is.na(HousePricing$BsmtExposure) & is.na(HousePricing$BsmtFinType1) & is.na(HousePricing$BsmtFinType2)))
HousePricing[!is.na(HousePricing$BsmtFinType1) & (is.na(HousePricing$BsmtCond)|is.na(HousePricing$BsmtQual)|is.na(HousePricing$BsmtExposure)|is.na(HousePricing$BsmtFinType2)), c('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2')]

HousePricing$BsmtFinType2[333] = names(sort(table(HousePricing$BsmtFinType2),decreasing = TRUE))[1]
HousePricing$BsmtExposure[949] = names(sort(table(HousePricing$BsmtExposure),decreasing = TRUE))[1]

HousePricing$BsmtQual[is.na(HousePricing$BsmtQual)] = 'None'
HousePricing$BsmtQual=recode(HousePricing$BsmtQual,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)

HousePricing$BsmtCond[is.na(HousePricing$BsmtCond)] = 'None'
HousePricing$BsmtCond=recode(HousePricing$BsmtCond,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)

HousePricing$BsmtExposure[is.na(HousePricing$BsmtExposure)]='None'
HousePricing$BsmtExposure=recode(HousePricing$BsmtExposure,'None' = 0,'No' = 1,'Mn' = 2,'Av' = 3,'Gd' = 4)

HousePricing$BsmtFinType1[is.na(HousePricing$BsmtFinType1)] = 'None'
HousePricing$BsmtFinType1=recode(HousePricing$BsmtFinType1,'None' = 0,'Unf' = 1,'LwQ' = 2,'Rec' = 3,'BLQ' = 4,'ALQ' = 5,'GLQ' = 6)

HousePricing$BsmtFinType2[is.na(HousePricing$BsmtFinType2)] = 'None'
HousePricing$BsmtFinType2=recode(HousePricing$BsmtFinType2,'None' = 0,'Unf' = 1,'LwQ' = 2,'Rec' = 3,'BLQ' = 4,'ALQ' = 5,'GLQ' = 6)


HousePricing$MasVnrType[is.na(HousePricing$MasVnrType)] = 'None'
median(HousePricing$SalePrice[HousePricing$MasVnrType=='BrkCmn'])
median(HousePricing$SalePrice[HousePricing$MasVnrType=='BrkFace'])
median(HousePricing$SalePrice[HousePricing$MasVnrType=='None'])
median(HousePricing$SalePrice[HousePricing$MasVnrType=='Stone'])
HousePricing$MasVnrType=recode(HousePricing$MasVnrType,'BrkCmn' = 0,'None' = 0,'BrkFace' = 1,'Stone' = 2)

HousePricing$MasVnrArea[(is.na(HousePricing$MasVnrArea))] = 0
HousePricing$Electrical[is.na(HousePricing$Electrical)] <- names(sort(-table(HousePricing$Electrical)))[1]
HousePricing$Electrical=as.factor(HousePricing$Electrical)

HousePricing$MSZoning = as.factor(HousePricing$MSZoning)
HousePricing$Street=recode(HousePricing$Street,'Pave' = 0,'Grvl' = 1)
HousePricing$LotShape=recode(HousePricing$LotShape,'IR3' = 0,'IR2' = 1,'IR1' = 2,'Reg' =2)
HousePricing$Utilities=recode(HousePricing$Utilities,'ELO' = 0,'NoSeWa' = 1,'NoSewr' = 2,'AllPub' =2)
HousePricing$LotConfig = as.factor(HousePricing$LotConfig)
HousePricing$Condition1 = as.factor(HousePricing$Condition1)
HousePricing$Condition2 = as.factor(HousePricing$Condition2)
HousePricing$LandContour = as.factor(HousePricing$LandContour)
HousePricing$RoofStyle = as.factor(HousePricing$RoofStyle)
HousePricing$LandSlope=recode(HousePricing$LandSlope,'Sev' = 0,'Mod' = 1,'Gtl' = 2)
HousePricing$BldgType = as.factor(HousePricing$BldgType)
HousePricing$HouseStyle=as.factor(HousePricing$HouseStyle)
HousePricing$RoofMatl=as.factor(HousePricing$RoofMatl)
HousePricing$Exterior1st=as.factor(HousePricing$Exterior1st)
HousePricing$Exterior2nd=as.factor(HousePricing$Exterior2nd)
HousePricing$ExterQual=recode(HousePricing$ExterQual,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$ExterCond=recode(HousePricing$ExterCond,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$Foundation = as.factor(HousePricing$Foundation)
HousePricing$Heating = as.factor(HousePricing$Heating)
HousePricing$HeatingQC=recode(HousePricing$HeatingQC,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$CentralAir=recode(HousePricing$CentralAir,'N' = 0,'Y' = 1)
HousePricing$KitchenQual=recode(HousePricing$KitchenQua,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$Functional=recode(HousePricing$Functional,'Sal' = 0,'Sev' = 1,'Maj2' = 2,'Maj1' = 3,'Mod' = 4,'Min2' = 5,'Min1' = 6,'Typ' = 7)
HousePricing$GarageType=as.factor(HousePricing$GarageType)

HousePricing$GarageFinish=recode(HousePricing$GarageFinish,'None' = 0,'Unf' = 1,'RFn' = 2,'Fin' = 3)
HousePricing$GarageCond=recode(HousePricing$GarageCond,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)
HousePricing$PavedDrive=recode(HousePricing$PavedDrive,'N' = 0,'P' = 1,'Y' = 2)
HousePricing$SaleType = as.factor(HousePricing$SaleType)
HousePricing$SaleCondition = as.factor(HousePricing$SaleCondition)
HousePricing$MoSold = as.factor(HousePricing$MoSold)
HousePricing$MSSubClass = as.factor(HousePricing$MSSubClass)
```

```{r fe2, include=FALSE}

combined_data = HousePricing

#colnames(combined_data)
#glue("Dimension of Combined Dataset : {dim(combined_data)}")

#glimpse(combined_data)
# check number of NAs in each column:
cbind(colSums(is.na(combined_data)))

# drop ID column from the dataset 
combined_data$Id = NULL
str(combined_data)
cbind(colSums(is.na(combined_data)))


# percentage of missing Values in dataset ####
cbind(colSums(is.na(combined_data)),colSums(is.na(combined_data))/(nrow(combined_data)) * 100)


# fixing Missing Values :
# MSZoning
# 4 missing values 
unique(combined_data$MSZoning)
table(combined_data$MSZoning)
# Most of the values are populated with RL
combined_data$MSZoning[is.na(combined_data$MSZoning)] = "RL"

# LotFrontage : 486 missing values
#glue("Mean of LotFrontage : {mean(combined_data$LotFrontage, na.rm = T)} and Median of LotFrontage : {median(combined_data$LotFrontage, na.rm = T)}")

neighbor_Median  = combined_data %>%
  select(LotFrontage, Neighborhood) %>%
  group_by(Neighborhood) %>%
  summarise(LotFrontage = median(LotFrontage, na.rm = T))

# alternative : 
# neighbor_Median = aggregate(LotFrontage ~ Neighborhood, data = combined_data, median)
for (i in 1:nrow(combined_data))
{
  if(is.na(combined_data$LotFrontage[i])){
    temp = combined_data$Neighborhood[i]
    combined_data$LotFrontage[i] = neighbor_Median$LotFrontage[neighbor_Median$Neighborhood == temp]
  }
  
}

# Alley has 93.21% missing data
# and as per data description, NA =  no alley access
# Create a third alley type but before that convert it to character
combined_data$Alley = as.character(combined_data$Alley)
combined_data$Alley[is.na(combined_data$Alley)] = "None"
combined_data$Alley = as.factor(combined_data$Alley)

# utilites :  type of utilities available 
combined_data$Utilities = as.factor(combined_data$Utilities)
unique(combined_data$Utilities)
table(combined_data$Utilities)

# One NA  and All other has AllPubs 
combined_data$Utilities[is.na(combined_data$Utilities)] = "AllPub"
# But single value: no vaiation 
#  Discard it 
combined_data$Utilities = NULL

unique(combined_data$Exterior1st)
table(combined_data$Exterior1st)

combined_data$SalePrice[is.na(combined_data$Exterior1st)]

which.max(table(combined_data$Exterior1st))

# its in testing data
combined_data$Exterior1st[is.na(combined_data$Exterior1st)] = "VinylSd"
unique(combined_data$Exterior2nd)
table(combined_data$Exterior2nd)
which.max(table(combined_data$Exterior2nd))

combined_data$Exterior2nd[is.na(combined_data$Exterior2nd)] = "VinylSd"

# MasVbeType
unique(combined_data$MasVnrType)
table(combined_data$MasVnrType)
combined_data$MasVnrType[is.na(combined_data$MasVnrType)] = "None"
# Mass Veneer Area : 23 NAs
unique(combined_data$MasVnrArea)
combined_data$MasVnrArea[is.na(combined_data$MasVnrArea)] = median(combined_data$MasVnrArea, na.rm = T)

# Basement Details ####
# Basement Criteria : None for NA
unique(combined_data$BsmtQual)
combined_data$BsmtQual = as.character(combined_data$BsmtQual)
combined_data$BsmtQual[is.na(combined_data$BsmtQual)] = "None"

unique(combined_data$BsmtCond)
combined_data$BsmtCond = as.character(combined_data$BsmtCond)
combined_data$BsmtCond[is.na(combined_data$BsmtCond)] = "None"

combined_data$BsmtExposure = as.character(combined_data$BsmtExposure)
combined_data$BsmtExposure[is.na(combined_data$BsmtExposure)] = "None"
combined_data$BsmtFinType1 = as.character(combined_data$BsmtFinType1)
combined_data$BsmtFinType1[is.na(combined_data$BsmtFinType1)] = "None"
combined_data$BsmtFinType2 = as.character(combined_data$BsmtFinType2)
combined_data$BsmtFinType2[is.na(combined_data$BsmtFinType2)] = "None"


combined_data$BsmtFinSF1[is.na(combined_data$BsmtFinSF1)] = median(combined_data$BsmtFinSF1, na.rm = T)

cbind(table(combined_data$BsmtFinSF2)) 
# most 0s
combined_data$BsmtFinSF2[is.na(combined_data$BsmtFinSF2)] = 0

unique(combined_data$BsmtUnfSF)
combined_data$BsmtUnfSF[is.na(combined_data$BsmtUnfSF)] = median(combined_data$BsmtUnfSF, na.rm = T)

unique(combined_data$TotalBsmtSF)
combined_data$TotalBsmtSF[is.na(combined_data$TotalBsmtSF)] = median(combined_data$TotalBsmtSF, na.rm = T)

unique(combined_data$BsmtFullBath)
table(combined_data$BsmtFullBath)
combined_data$BsmtFullBath[is.na(combined_data$BsmtFullBath)] = 0

unique(combined_data$BsmtHalfBath)
table(combined_data$BsmtHalfBath)
combined_data$BsmtHalfBath[is.na(combined_data$BsmtHalfBath)] = 0

# Kitchen ####
unique(combined_data$KitchenQual)
table(combined_data$KitchenQual)
combined_data$KitchenQual[is.na(combined_data$KitchenQual)] = "TA"

## Electrical ####
unique(combined_data$Electrical)
table(combined_data$Electrical)
combined_data$Electrical[is.na(combined_data$Electrical)] = "SBrkr"

# functional
unique(combined_data$Functional)
table(combined_data$Functional)
combined_data$Functional[is.na(combined_data$Functional)] = "Typ"

unique(combined_data$FireplaceQu)
table(combined_data$FireplaceQu)
combined_data$FireplaceQu[is.na(combined_data$FireplaceQu)] = "None"

# Garage ####
unique(combined_data$GarageType)
table(combined_data$GarageType)
combined_data$GarageType[is.na(combined_data$GarageType)] = "None"

combined_data$GarageYrBlt[is.na(combined_data$GarageYrBlt)] = 0

table(combined_data$GarageFinish)
combined_data$GarageFinish[is.na(combined_data$GarageFinish)] = "None"

combined_data$GarageArea[is.na(combined_data$GarageArea)] = 0 
combined_data$GarageCars[is.na(combined_data$GarageCars)] = 0
combined_data$GarageQual[is.na(combined_data$GarageQual)] = "None"
combined_data$GarageCond[is.na(combined_data$GarageCond)] = "None"

# Misclenneous #####
combined_data$PoolQC[is.na(combined_data$PoolQC)] = "None"
combined_data$Fence[is.na(combined_data$Fence)] = "None"
combined_data$MiscFeature[is.na(combined_data$MiscFeature)] = "None"
combined_data$MiscVal


# sales type ####
unique(combined_data$SaleType)
table(combined_data$SaleType)
combined_data$SaleType[is.na(combined_data$SaleType)] = 'WD'


# Changing characters to Factors variables
# apply(combined_data,1, function(x){ if(class(x) == "character"){x = as.factor(x)}})
combined_data = as.data.frame(unclass(combined_data))

# some numeric data to factor
combined_data$MSSubClass = as.factor(combined_data$MSSubClass)

```



```{r prepareNewData}
numvar = which(sapply(combined_data, is.numeric))
catvar = which(sapply(combined_data, is.factor))
numdata = combined_data[,numvar]
numcor =(cor(numdata))
corsorted = as.matrix(sort(numcor[,"SalePrice"],decreasing = TRUE))
CorHigh <- names(which(apply(corsorted, 1, function(x) abs(x)>0.5)))
numcor <- numcor[CorHigh, CorHigh]
corrplot.mixed(numcor, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)
temp = subset(combined_data,select=-SalePrice)
# standardize numerical data 
numeric = select_if(temp,is.numeric)
stnumer = scale(numeric,center = T,scale = T)
convFact = select_if(temp,is.factor)
# one hot
convFact = model.matrix(~.-1,convFact) %>% data.frame()
SalePrice = combined_data$SalePrice
# put standardized numerical data and categorical data in one data?
newdata = cbind(stnumer,convFact,SalePrice)

```

### Boostraping

```{r bootstraping}
set.seed(1234)
sample = sample(dim(newdata)[1],dim(newdata)[1],replace = T)
btnewdata = newdata[sample,]
```


### Seperate into Test and Training Set

Spearate by 70% train, 30% test. 

Convert to CSV upload

```{r prepareClassification}
clbtnewdata=transform(btnewdata,SalePrice=ifelse(SalePrice>168000,1,0))
```

```{r separateDataReg}
set.seed(1)
randS = sample(1:nrow(btnewdata), nrow(btnewdata)*0.7)
train = btnewdata[randS,]
test = btnewdata[-randS,]
```

```{r separateDataClass}
set.seed(12345)
randS = sample(1:nrow(clbtnewdata), nrow(btnewdata)*0.7)
trainCl = clbtnewdata[randS,]
testCl = clbtnewdata[-randS,]
```

```{r writeToCSV}
#write.csv(trainCl,"./SourceData/train_p_cl.csv", row.names = FALSE)
#write.csv(testCl,"./SourceData/test_p_cl.csv", row.names = FALSE)
```

```{r newCSVTestTrainReg}
test = read.csv("./SourceData/test_p2.csv")
y_test = test$SalePrice
x_test = subset (test, select = -SalePrice)
train = read.csv("./SourceData/train_p2.csv")
y_train = train$SalePrice
x_train = subset (train, select = -SalePrice)
y_train = as.numeric(y_train)
y_test = as.numeric(y_test)
summary(y_train)
```

```{r newCSVTestTrainCl}
test_cl = read.csv("./SourceData/test_p_cl.csv")
y_test_cl = test$SalePrice
x_test_cl = subset (test, select = -SalePrice)
train_cl = read.csv("./SourceData/train_p_cl.csv")
y_train_cl = train_cl$SalePrice
x_train_cl = subset (train, select = -SalePrice)
y_train_cl = as.factor(y_train_cl)
y_test_cl = as.factor(y_test_cl)
summary(y_train_cl)
```

## Hierachical

Each team member bootstraps training data. 

## Prediction Algorithms

Each model needs a cross validation algorithm
Remember to report RMSE

### Regression Methods

#### 1. PCR (Iris)

```{r PCR}
set.seed(2)
# Need help with PCA analysis
# pcr.fit=pcr(SalePrice~., data=HousePricing, scale=TRUE, validation ="CV")
```

##### Cross Validation

#### 2. Random Forest (Yufei Lin)

##### Prepare Model

We have $199$ independent variables in the data set, therefore we have set mtry(Number of randomly selected variables for each split) to be the square root of that number for maximum performance of the model. 

```{r rf-preparemodel}
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train))
rfTrain=randomForest(SalePrice~.,data=train, mtry=sqrt(totalIV)+1000,importance =TRUE)
pander(rfTrain)
```

##### Check Accuracy

If we raise the allowance to $\$$10000 We could raise the prediction accuracy to almost 95% of a time.

```{r rfAccuracy}
rfYhat = predict(rfTrain, newdata=x_test)
head(rfYhat)
head(y_test)
#table(y_test, rfYhat)
accuracy = mean(abs(y_test - rfYhat)/y_test<=0.05)
accuracy
```

##### Error Metrics

Then let us take a look at the MSE of this model: 
```{r rfMSE}
#rfYhat = predict(rfTrain ,newdata=test)
print("The test MSE is shown in the following: ")
mean((rfYhat-test$SalePrice)^2)
```

##### Variable Importance

Here we are going to show the top 10 most important variables in predicting sale price of a house.

```{r rfVarImportance1}
importance = importance(rfTrain)
varImportance = head(data.frame(Variables = row.names(importance),
 Importance =round(importance[, "%IncMSE"],1)),10)
rankImportance=varImportance%>%mutate(Rank=paste('#',dense_rank(desc(Importance))))
ggplot(rankImportance,aes(x=reorder(Variables,Importance),
 y=Importance,fill=Importance))+ 
 geom_bar(stat='identity') + 
 geom_text(aes(x = Variables, y = 0.5, label = Rank),
 hjust=0, vjust=0.55, size = 4, colour = 'white') +
 labs(x = 'Variables') +
 coord_flip() + 
 theme_classic()
```


From the random forest analysis, we have discovered that the top three most important factors for predicting sale price are the following:

\begin{enumerate}
\item OverallQual
\item LotArea
\item GrLivArea
\item Neighbourhood
\end{enumerate}

##### Cross Validation

```{r RFCV}
set.seed(123) 
  
# computing model performance metrics 
data.frame( R2 = R2(rfYhat, y_test), 
            RMSE = RMSE(rfYhat, y_test), 
            MAE = MAE(rfYhat, y_test)) 
```


Therefore, we will make GAM models according to these three factors. 

#### 3. GAM (Yufei Lin)

1) GAM1

```{r GAM1}
fit1 = gam(SalePrice ~ s(LotFrontage) + s(LotArea) + OverallQual, data = train)
print("Deviance of Model 1")
deviance(fit1)
pred1 = predict(fit1, newdata=x_test)
accuracy = mean(abs(y_test - pred1)/y_test<=0.05)
print("Accuracy of Model 1")
accuracy
plot(fit1 , se=TRUE , col="red")
```

2) GAM1

```{r GAM2}
fit2 = gam(SalePrice ~ OverallCond + s(LotArea) + OverallQual, data = train)
print("Deviance of Model 2")
deviance(fit2)
pred2 = predict(fit2, newdata=x_test)
accuracy = mean(abs(y_test - pred2)/y_test<=0.05)
print("Accuracy of Model 2")
accuracy
plot(fit2 , se=TRUE , col="red")
```

3) GAM3

```{r GAM3}
fit3 = gam(SalePrice ~ LotFrontage + YearRemodAdd + OverallQual, data = train)
print("Deviance of Model 3")
deviance(fit3)
pred3 = predict(fit3, newdata=x_test)
accuracy = mean(abs(y_test - pred3)/y_test<=0.05)
print("Accuracy of Model 3")
accuracy
#plot(fit3 , se=TRUE , col="red")
```

GAM Summary

```{r GAMSummary}
anova(fit1,fit2,fit3,test="F")
```
From this we know that the deviance is quite large, we need a better model. 

##### Cross Validation

```{r GAMCV}
set.seed(123) 

# computing model performance metrics 
print("Cross Validation of Model 1")
data.frame( R2 = R2(pred1, y_test), 
            RMSE = RMSE(pred1, y_test), 
            MAE = MAE(pred1, y_test))

print("Cross Validation of Model 2")
data.frame( R2 = R2(pred2, y_test), 
            RMSE = RMSE(pred2, y_test), 
            MAE = MAE(pred2, y_test))

print("Cross Validation of Model 3")
data.frame( R2 = R2(pred3, y_test), 
            RMSE = RMSE(pred3, y_test), 
            MAE = MAE(pred3, y_test))
```

#### 4. Lasso & Ridge (Jinhong)

```{r LassoRidge}
#LASSO
LassoAlpha=1
LassoLambda = 10^(seq(3,-1,length=100))
set.seed(12)
XTrain = model.matrix(SalePrice~.,data = train)[,-1]
XTest = model.matrix(SalePrice~.,test)[,-1]
YTrain = train$SalePrice
YTest = test$SalePrice
set.seed(123)
LassoFit = glmnet(XTrain, YTrain, alpha=LassoAlpha, lambda=LassoLambda)
LassoFitcv = cv.glmnet(XTrain, YTrain, alpha = LassoAlpha, lambda = LassoLambda)
bestlambda = LassoFitcv$lambda.min;bestlambda
plot(LassoFitcv)
LassoPred <- predict(LassoFit, s= bestlambda, newx = XTest)
sqrt(mean((LassoPred -YTest)^2))
predict(LassoFit, s = bestlambda, type="coefficients")
```

##### Cross Validation

#### 5. Splines (Jingfeng)

##### Cross Validation

#### 6. Linear Regression (Yanze)

```{r LRPreparModel1}
lm_model = lm(formula = SalePrice ~.,data = train)
summary(lm_model)
```

```{r LRPreparModel2}
# Multiple R-squared: 0.9475, 
# Adjusted R-squared: 0.9345  
# F-statistic:  73.09  on 289 and 1170 DF, 
# p-value: < 2.2e-16

lm_pred = predict(lm_model, newdata = as.data.frame(test))
#lm_pred  = exp(lm_pred)
lm_pred
#result_lm_model = data.frame(Id = testing_data$Id, SalePrice = lm_pred)
```

##### Cross Validation

#### 7. Ensemble

### Classifcation Methods

#### 1. Support Vector Machine
```{r svm}
library(e1071)
svmfit=svm(SalePrice~., data=train_cl , kernel="linear", cost=10,
scale=FALSE)
svmfit

```

## Evaluation of different models

Root MSE

## Choose best fit model

## Discussion & Future Development

## Resources
https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda































































