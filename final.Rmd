---
title: "House Pricing Prediction"
subtitle: "DS502 Final Project"
author: "Yufei Lin, Jingfeng Xia, Jinhong Yu, Shijing Yang, Yanze Wang"
date: "Nov 29 2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
# check R version
R.Version()$major

# set up document
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
library(pander)
library(knitr)
library(skimr)
library(kableExtra)
library(tinytex)
library(dplyr)
library(purrr)
local({
  hook_inline = knitr::knit_hooks$get('inline')
  knitr::knit_hooks$set(inline = function(x) {
    res = hook_inline(x)
    if (is.numeric(x)) sprintf('$%s$', res) else res
  })
})

# define printf function
printf <- function(...)print(sprintf(...))
```

```{r libraries, include=FALSE}
# Import model libraries
library(pls)
library(randomForest)
library(gam)
library(glmnet)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(caret)
library(mgcv)
library(Metrics)
library(visreg)
library('ggthemes') 
library('scales')
library('mice')
library('data.table')
library('gridExtra') 
library('GGally')
library('e1071')
```

# Introduction

## Description of the Problem

Being able to predict the price of a house tends to be an important skill for both the seller and consumers. For the seller, they could make better sales and consumers could have better understanding when they try to make a purchase. Therefore, in this project, we are planning to make prediction of house price based on the 79 different predictors provided by Kaggle dataset to determine values of residential homes in Ames, Iowa. We are planning to use PCA, Cross-validation, Linear regression, and Ridge and LASSO regression for prediction. Furthermore, we will be utilizing decision trees for more accurate prediction result as a comparison with other methods.

## Description of the Dataset

In terms of the dataset, the entire data set consists of two pieces of data organized as training data set and test data set respectively. Whereas for each of the dataset, approximately 80 columns corresponding parameters would be evaluated with the prediction of house price. Some noteworthy predictors include the location classification, utilities, environment of neighborhood, house style and condition, area, year of built, and number of functioning rooms. There are over 1400 row data points in both the training data set and the test data set. The sale prices in the train dataset are given as a parameter in the form of five or six figure full flat integers. The test data set will be applied to different regression models in order to distinguish the disparities of different model performances. 
    
## Approaches

Given that our data is aimed at predicting Sale Price of a house, it is unreasonable to require a model to fit the exact value of the dataset but only to reach an estimation within a certain range. Therefore, we have decided to use both regression and classification approaches to look at the problem. For regression method, we are going to look at if a prediction is within the range of the actual price $\pm 5\%$, we will say it is an accurate prediction. For classification prediction, we will be tagging the data into several different groups, and would be fitting the threshold accordingly with models like SVM. 

# Data Processing

## Read in Data

We have chosen to eliminate the Id column from this dataset because Id has nothing to do with our prediction and would mess up our prediction. And we store the "test.csv" data in a variable \textbf{vault} for future testing, and save the "train.csv"" data from Kaggle to a variable named \textbf{HousePricing} for further processing.  

```{r readData}
vault = read.csv("./SourceData/test.csv")
vault = subset(vault, select=-Id)
HousePricing = read.csv("./SourceData/train.csv")
HousePricing = subset(HousePricing,select=-Id)
```

## Data Exploration

```{r dimensionOfData}
# The number of columns and rows
paste("Original training data set has",dim(HousePricing)[1], "rows and", dim(HousePricing)[2], "columns")

# The percentage of data missing in train
paste("The percentage of data missing in the original training data set is ", round(sum(is.na(HousePricing)) / (nrow(HousePricing) *ncol(HousePricing)),4)*100,"%",sep = "")

# The number of duplicated rows
paste("The number of duplicated rows are", nrow(HousePricing) - nrow(unique(HousePricing)))
```

```{r numOfNumericAndFactors}
print("Number of Factors:")
sum(sapply(HousePricing[,1:80],typeof) == "character")
print("Number of Numeric:")
sum(sapply(HousePricing[,1:80],typeof) == "integer")
```
```{r summaryOfData}
pander(summary(HousePricing[,sapply(HousePricing[,1:80],typeof) == "integer"]))
```



```{r visualization}
# data visualization
cat.var = names(HousePricing)[which(sapply(HousePricing, is.character))]
num.var = names(HousePricing)[which(sapply(HousePricing, is.numeric))]
train.num = HousePricing[num.var]
train.cat = HousePricing[cat.var]

## Bar plot/Density plot function

## Bar plot function

plotHist <- function(data_in, i) 
{
  data <- data.frame(x=data_in[[i]])
  p <- ggplot(data=data, aes(x=factor(x))) + stat_count() + xlab(colnames(data_in)[i]) + theme_light() + 
    theme(axis.text.x = element_text(angle = 90, hjust =1))
  return (p)
}

## Density plot function

plotDen <- function(data_in, i){
  data <- data.frame(x=data_in[[i]], SalePrice = data_in$SalePrice)
  p <- ggplot(data= data) + geom_line(aes(x = x), stat = 'density', size = 1,alpha = 1.0) +
    xlab(paste0((colnames(data_in)[i]), '\n', 'Skewness: ',round(skewness(data_in[[i]], na.rm = TRUE), 2))) + theme_light() 
  return(p)
  
}

## Function to call both Bar plot and Density plot function

doPlots <- function(data_in, fun, ii, ncol=3) 
{
  pp <- list()
  for (i in ii) {
    p <- fun(data_in=data_in, i=i)
    pp <- c(pp, list(p))
  }
  do.call("grid.arrange", c(pp, ncol=ncol))
}

```

```{r plotting}
# barplots for categorical features
doPlots(train.cat, fun = plotHist, ii = 1:4, ncol = 2)

doPlots(train.cat, fun = plotHist, ii = 5:8, ncol = 2)

doPlots(train.cat, fun = plotHist, ii = 9:12, ncol = 2)

doPlots(train.cat, fun = plotHist, ii = 13:18, ncol = 2)

doPlots(train.cat, fun = plotHist, ii = 19:22, ncol = 2)
```

```{r plot}

# boxplots

ggplot(HousePricing, aes(x = Neighborhood, y = SalePrice)) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
             colour='red', linetype='dashed', lwd=2) +
  scale_y_continuous(labels=dollar_format()) +
  theme_few()

# conclusion: boxplot between the neighboorhoods and sale price shows that BrookSide and 
# South & West of Iowa State University have cheap houses. 
# While Northridge and Northridge Heights are rich neighborhoods with several outliers in terms of price.

# density plots for numeric variables
doPlots(train.num, fun = plotDen, ii = 2:6, ncol = 2)
doPlots(train.num, fun = plotDen, ii = 7:12, ncol = 2)
doPlots(train.num, fun = plotDen, ii = 13:17, ncol = 2)

# Conclusion: Density plots of the features indicates that the features are skewed. 
# The denisty plot for YearBuilt shows that the data set contains a mix of new and old houses. 
# It shows a downturn in the number of houses in recent years, possibily due to the housing crisis.

doPlots(train.num, fun = plotHist, ii = 18:23, ncol = 2)

# Conclusion: The histograms below show that majority of the houses have 2 full baths, 0 half baths, 
# and have an average of 3 bedrooms.

# Explore correlation

correlation = cor(na.omit(train.num))
row_indic = apply(correlation, 1, function(x) sum(x > 0.3 | x < -0.3) > 1)
correlation = correlation[row_indic,row_indic]
corrplot(correlation,method = "shade")

```

### target varaible vs. predictors

```{r targetvspredictors}
summary(HousePricing$SalePrice)
quantile(HousePricing$SalePrice)
hist(HousePricing$SalePrice,col="blue",breaks = 25,main = "Distribution of SalePrice", xlab = "Sale Price")
```

\textbf{Conclusion}

It deviates from normal distribution and it is right skewed

# Plotting 'GrLivArea' too see if there are any outliers

```{r outlier}
qplot(GrLivArea, SalePrice, data= HousePricing,col=GrLivArea>4000,xlab = "GrLivArea", ylab="Sale Price",main = "Living Area vs. Sale Price")

summary(HousePricing$GrLivArea)
hist(HousePricing$GrLivArea,breaks = 20,xlab="Living area",col = "dark red",main = "Frequency of Living area square feet")
```

## Feature Engineering

We choose to take the log of Sale Price, our y-value. 

In this section, we convert all missing value based on the following rules:

\begin{enumerate}
\item Categorical: fill in most common
\item Numeric: fill in median/average
\end{enumerate}

Convert all train to HousePricing

```{r fe, include=FALSE}

combined_data = HousePricing

#colnames(combined_data)
#glue("Dimension of Combined Dataset : {dim(combined_data)}")

#glimpse(combined_data)
# check number of NAs in each column:
cbind(colSums(is.na(combined_data)))

# drop ID column from the dataset 
combined_data$Id = NULL
str(combined_data)
cbind(colSums(is.na(combined_data)))


# percentage of missing Values in dataset ####
cbind(colSums(is.na(combined_data)),colSums(is.na(combined_data))/(nrow(combined_data)) * 100)


# fixing Missing Values :
# MSZoning
# 4 missing values 
unique(combined_data$MSZoning)
table(combined_data$MSZoning)
# Most of the values are populated with RL
combined_data$MSZoning[is.na(combined_data$MSZoning)] = "RL"

# LotFrontage : 486 missing values
#glue("Mean of LotFrontage : {mean(combined_data$LotFrontage, na.rm = T)} and Median of LotFrontage : {median(combined_data$LotFrontage, na.rm = T)}")

neighbor_Median  = combined_data %>%
  select(LotFrontage, Neighborhood) %>%
  group_by(Neighborhood) %>%
  summarise(LotFrontage = median(LotFrontage, na.rm = T))

# alternative : 
# neighbor_Median = aggregate(LotFrontage ~ Neighborhood, data = combined_data, median)
for (i in 1:nrow(combined_data))
{
  if(is.na(combined_data$LotFrontage[i])){
    temp = combined_data$Neighborhood[i]
    combined_data$LotFrontage[i] = neighbor_Median$LotFrontage[neighbor_Median$Neighborhood == temp]
  }
  
}

# Alley has 93.21% missing data
# and as per data description, NA =  no alley access
# Create a third alley type but before that convert it to character
combined_data$Alley = as.character(combined_data$Alley)
combined_data$Alley[is.na(combined_data$Alley)] = "None"
combined_data$Alley = as.factor(combined_data$Alley)

# utilites :  type of utilities available 
combined_data$Utilities = as.factor(combined_data$Utilities)
unique(combined_data$Utilities)
table(combined_data$Utilities)

# One NA  and All other has AllPubs 
combined_data$Utilities[is.na(combined_data$Utilities)] = "AllPub"
# But single value: no vaiation 
#  Discard it 
combined_data$Utilities = NULL

unique(combined_data$Exterior1st)
table(combined_data$Exterior1st)

combined_data$SalePrice[is.na(combined_data$Exterior1st)]

which.max(table(combined_data$Exterior1st))

# its in testing data
combined_data$Exterior1st[is.na(combined_data$Exterior1st)] = "VinylSd"
unique(combined_data$Exterior2nd)
table(combined_data$Exterior2nd)
which.max(table(combined_data$Exterior2nd))

combined_data$Exterior2nd[is.na(combined_data$Exterior2nd)] = "VinylSd"

# MasVbeType
unique(combined_data$MasVnrType)
table(combined_data$MasVnrType)
combined_data$MasVnrType[is.na(combined_data$MasVnrType)] = "None"
# Mass Veneer Area : 23 NAs
unique(combined_data$MasVnrArea)
combined_data$MasVnrArea[is.na(combined_data$MasVnrArea)] = median(combined_data$MasVnrArea, na.rm = T)

# Basement Details ####
# Basement Criteria : None for NA
unique(combined_data$BsmtQual)
combined_data$BsmtQual = as.character(combined_data$BsmtQual)
combined_data$BsmtQual[is.na(combined_data$BsmtQual)] = "None"

unique(combined_data$BsmtCond)
combined_data$BsmtCond = as.character(combined_data$BsmtCond)
combined_data$BsmtCond[is.na(combined_data$BsmtCond)] = "None"

combined_data$BsmtExposure = as.character(combined_data$BsmtExposure)
combined_data$BsmtExposure[is.na(combined_data$BsmtExposure)] = "None"
combined_data$BsmtFinType1 = as.character(combined_data$BsmtFinType1)
combined_data$BsmtFinType1[is.na(combined_data$BsmtFinType1)] = "None"
combined_data$BsmtFinType2 = as.character(combined_data$BsmtFinType2)
combined_data$BsmtFinType2[is.na(combined_data$BsmtFinType2)] = "None"


combined_data$BsmtFinSF1[is.na(combined_data$BsmtFinSF1)] = median(combined_data$BsmtFinSF1, na.rm = T)

cbind(table(combined_data$BsmtFinSF2)) 
# most 0s
combined_data$BsmtFinSF2[is.na(combined_data$BsmtFinSF2)] = 0

unique(combined_data$BsmtUnfSF)
combined_data$BsmtUnfSF[is.na(combined_data$BsmtUnfSF)] = median(combined_data$BsmtUnfSF, na.rm = T)

unique(combined_data$TotalBsmtSF)
combined_data$TotalBsmtSF[is.na(combined_data$TotalBsmtSF)] = median(combined_data$TotalBsmtSF, na.rm = T)

unique(combined_data$BsmtFullBath)
table(combined_data$BsmtFullBath)
combined_data$BsmtFullBath[is.na(combined_data$BsmtFullBath)] = 0

unique(combined_data$BsmtHalfBath)
table(combined_data$BsmtHalfBath)
combined_data$BsmtHalfBath[is.na(combined_data$BsmtHalfBath)] = 0

# Kitchen ####
unique(combined_data$KitchenQual)
table(combined_data$KitchenQual)
combined_data$KitchenQual[is.na(combined_data$KitchenQual)] = "TA"

## Electrical ####
unique(combined_data$Electrical)
table(combined_data$Electrical)
combined_data$Electrical[is.na(combined_data$Electrical)] = "SBrkr"

# functional
unique(combined_data$Functional)
table(combined_data$Functional)
combined_data$Functional[is.na(combined_data$Functional)] = "Typ"

unique(combined_data$FireplaceQu)
table(combined_data$FireplaceQu)
combined_data$FireplaceQu[is.na(combined_data$FireplaceQu)] = "None"

# Garage ####
unique(combined_data$GarageType)
table(combined_data$GarageType)
combined_data$GarageType[is.na(combined_data$GarageType)] = "None"

combined_data$GarageYrBlt[is.na(combined_data$GarageYrBlt)] = 0

table(combined_data$GarageFinish)
combined_data$GarageFinish[is.na(combined_data$GarageFinish)] = "None"

combined_data$GarageArea[is.na(combined_data$GarageArea)] = 0 
combined_data$GarageCars[is.na(combined_data$GarageCars)] = 0
combined_data$GarageQual[is.na(combined_data$GarageQual)] = "None"
combined_data$GarageCond[is.na(combined_data$GarageCond)] = "None"

# Misclenneous #####
combined_data$PoolQC[is.na(combined_data$PoolQC)] = "None"
combined_data$Fence[is.na(combined_data$Fence)] = "None"
combined_data$MiscFeature[is.na(combined_data$MiscFeature)] = "None"
combined_data$MiscVal


# sales type ####
unique(combined_data$SaleType)
table(combined_data$SaleType)
combined_data$SaleType[is.na(combined_data$SaleType)] = 'WD'


# Changing characters to Factors variables
# apply(combined_data,1, function(x){ if(class(x) == "character"){x = as.factor(x)}})
combined_data = as.data.frame(unclass(combined_data))

# some numeric data to factor
combined_data$MSSubClass = as.factor(combined_data$MSSubClass)

```



```{r prepareNewData, fig.width=5,fig.height=3}
numvar = which(sapply(combined_data, is.numeric))
catvar = which(sapply(combined_data, is.factor))
numdata = combined_data[,numvar]
numcor =(cor(numdata))
corsorted = as.matrix(sort(numcor[,"SalePrice"],decreasing = TRUE))
CorHigh <- names(which(apply(corsorted, 1, function(x) abs(x)>0.5)))
numcor <- numcor[CorHigh, CorHigh]
corrplot.mixed(numcor, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)
temp = subset(combined_data,select=-SalePrice)
# standardize numerical data 
numeric = select_if(temp,is.numeric)
stnumer = scale(numeric,center = T,scale = T)
convFact = select_if(temp,is.factor)
# one hot
convFact = model.matrix(~.-1,convFact) %>% data.frame()
SalePrice = log(combined_data$SalePrice)
# put standardized numerical data and categorical data in one data?
newdata = cbind(stnumer,convFact,SalePrice)

```

## Boostraping

```{r bootstraping}
set.seed(1234)
sample = sample(dim(newdata)[1],dim(newdata)[1],replace = T)
btnewdata = newdata[sample,]
```


## Seperate into Test and Training Set

Spearate by 70% train, 30% test. 

```{r prepareClassification}
# clbtnewdata=transform(btnewdata,SalePrice=ifelse(SalePrice>168000,1,0))
```

```{r separateDataReg}
#set.seed(1)
#randS = sample(1:nrow(btnewdata), nrow(btnewdata)*0.7)
#train = btnewdata[randS,]
#test = btnewdata[-randS,]
```

```{r separateDataClass}
#set.seed(12345)
#randS = sample(1:nrow(clbtnewdata), nrow(btnewdata)*0.7)
#trainCl = clbtnewdata[randS,]
#testCl = clbtnewdata[-randS,]
```

```{r writeToCSV}
#write.csv(train,"./SourceData/train_p3.csv", row.names = FALSE)
#write.csv(test,"./SourceData/test_p3.csv", row.names = FALSE)
```

```{r newCSVTestTrainReg}
test = read.csv("./SourceData/test_p3.csv")
y_test = test$SalePrice
x_test = subset (test, select = -SalePrice)
train = read.csv("./SourceData/train_p3.csv")
y_train = train$SalePrice
x_train = subset (train, select = -SalePrice)
y_train = as.numeric(y_train)
y_test = as.numeric(y_test)
summary(y_train)
```

```{r newCSVTestTrainCl}
test_cl = read.csv("./SourceData/test_p_cl.csv")
y_test_cl = test$SalePrice
x_test_cl = subset (test, select = -SalePrice)
train_cl = read.csv("./SourceData/train_p_cl.csv")
y_train_cl = train_cl$SalePrice
x_train_cl = subset (train, select = -SalePrice)
y_train_cl = as.factor(y_train_cl)
y_test_cl = as.factor(y_test_cl)
summary(y_train_cl)
```

# Hierachical

Each team member bootstraps training data. 

# Prediction Algorithms

We choose to use PCR, Random Forest, GAM, Lasso and Ridge, Splines and Linear Regression to look at how each model would be suitable for our regression analysis. 

Each model needs a cross validation algorithm
Remember to report RMSE

## Regression Methods

### 1. PCR (Iris)

```{r PCR}
set.seed(2)
# Need help with PCA analysis
# pcr.fit=pcr(SalePrice~., data=HousePricing, scale=TRUE, validation ="CV")
```

#### Cross Validation

### 2. Random Forest

#### Explanation

We have chosen this model because random forest is based on a collection of decision trees that could help us get better understanding of which tree and division contribute to which section such that we could have a better picture of the overall importance of each different factor in the prediction.

#### Prepare Model

We have $199$ independent variables in the data set, therefore we have set mtry(Number of randomly selected variables for each split) to be the square root of that number for maximum performance of the model. 

The following is the result from Random Forest algorithm: 

```{r rf-preparemodel}
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train))
rfTrain=randomForest(SalePrice~.,data=train, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain)
```

#### Check Accuracy

We then need to check accuracy, as assumed before, we would look at whether the predicted data is within the $\pm 5\%$ range. The following is the result. 

```{r rfAccuracy}
rfYhat = predict(rfTrain, newdata=x_test)
#table(y_test, rfYhat)
accuracy = mean(abs(y_test - rfYhat)/y_test<=0.05)
printf("We have the accuracy of the model approximately %.2f%%", accuracy*100)
```

#### Error Metrics

Then let us take a look at the MSE of this model: 
```{r rfMSE}
printf("We have the MSE of the model approximately %.5f", mean((rfYhat-test$SalePrice)^2))

```

#### Variable Importance

Here we are going to show the top 10 most important variables in predicting sale price of a house.

```{r rfVarImportance1, fig.width=5,fig.height=3}
importance = importance(rfTrain)
varImportance = head(data.frame(Variables = row.names(importance),
 Importance =round(importance[, "%IncMSE"],1)),10)
rankImportance=varImportance%>%mutate(Rank=paste('#',dense_rank(desc(Importance))))
ggplot(rankImportance,aes(x=reorder(Variables,Importance),
 y=Importance,fill=Importance))+ 
 geom_bar(stat='identity') + 
 geom_text(aes(x = Variables, y = 0.5, label = Rank),
 hjust=0, vjust=0.55, size = 4, colour = 'white') +
 labs(x = 'Variables') +
 coord_flip() + 
 theme_classic()
```


From the random forest analysis, we have discovered that the top three most important factors for predicting sale price are the following:

\begin{enumerate}
\item OverallQual (Overall Quality of the building)
\item BsmtFinSF1 (Type 1 finished square feet)
\item LotArea (Area of Parking Lot of the Building)
\end{enumerate}

#### Cross Validation

In the cross validation, we have chosen to look at $R^2$, RMSE and MAE. 

```{r RFCV}
set.seed(123) 
  
# computing model performance metrics 
pander(data.frame( R2 = R2(rfYhat, y_test), 
            RMSE = RMSE(rfYhat, y_test), 
            MAE = MAE(rfYhat, y_test)), title="Cross Validation for Random Forest")
```

### 3. GAM

#### Explanation

We have chosen GAM as one of our models because it produces an analysis on those factors that have less linear relationship with the result, for instance LotFrontage, YearRemodAdd, and MasVnrArea that are having relatively high importance but also high p-value that makes them not very linear related to SalePrice. 

1) GAM1

In this model, we have LotFrontage, YearRemodAdd and MasVnrArea as predictors, with YearRemodAdd having a degree of freedom 2. We obtain the following result:

```{r GAM1, fig.width=5,fig.height=6}
fit1 = gam(SalePrice ~ s(LotFrontage) + ns(YearRemodAdd,2) + MasVnrArea, data = train)
printf("Deviance of Model 1 approximately %.2f", deviance(fit1))
pred1 = predict(fit1, newdata=x_test)
par(mfrow=c(2,1))
accuracy = mean(abs(y_test - pred1)/y_test<=0.05)
printf("Accuracy of Model 1 approximately %.2f%%", accuracy*100)
plot(fit1 , se=TRUE , col="red")
```

2) GAM2

In this model, we have LotFrontage, YearRemodAdd and MasVnrArea as predictors. None of them has a degree of freedom in the fit. We obtain the following result:

```{r GAM2, fig.width=5,fig.height=3}
fit2 = gam(SalePrice ~ LotFrontage + YearRemodAdd + s(MasVnrArea), data = train)
printf("Deviance of Model 2 approximately %.2f", deviance(fit2))
pred2 = predict(fit2, newdata=x_test)
accuracy = mean(abs(y_test - pred2)/y_test<=0.05)
printf("Accuracy of Model 2 approximately %.2f%%", accuracy*100)
plot(fit2 , se=TRUE , col="red")
```

3) GAM3

In this model, we have LotFrontage, YearRemodAdd and MasVnrArea as predictorswith LotFrontage having a degree of freedom of 3. We obtain the following result:

```{r GAM3, fig.width=5,fig.height=3}
fit3 = gam(SalePrice ~ ns(LotFrontage,3) + YearRemodAdd + s(MasVnrArea), data = train)
printf("Deviance of Model 3 approximately %.2f", deviance(fit3))
pred3 = predict(fit3, newdata=x_test)
accuracy = mean(abs(y_test - pred3)/y_test<=0.05)
printf("Accuracy of Model 3 approximately %.2f%%", accuracy*100)
plot(fit3 , se=TRUE , col="red")
```

GAM Summary

We then take an ANOVA test to understand which model is the best and we have the following result:

```{r GAMSummary}
anova(fit1,fit2,fit3,test="F")
```
We can see that from the anova test that P-value for the second model is the smallest, therefore, it is the most preferred.  

#### Cross Validation

Then, we conduct a cross-validation on the second model only. 

```{r GAMCV}
set.seed(123) 

pander(data.frame( R2 = R2(pred2, y_test), 
            RMSE = RMSE(pred2, y_test), 
            MAE = MAE(pred2, y_test)), title="Cross Validation of Model 2")
```

### 4. Ridge Regression

#### Explanation

The reason we choose Ridge regression model is Ridge regression is very similar to linear regression, both try to minimize the RSS, but ridge regression has a penalty term, this could help us to prevent overfitting when add more predictors.

#### Prepare Model

1. Bootstrap Training Data

```{r ridgebs}
set.seed(2)
bs = sample(dim(train)[1],dim(train)[1],replace = T)
train = train[bs,]

X_train = model.matrix(SalePrice~.,data = train)[,-1]
X_test = model.matrix(SalePrice~.,test)[,-1]
y_train = train$SalePrice
y_test = test$SalePrice
```

1. First, we set initial alpha to 1 to fit the ridge regression,and set the values of initial lambda ranging from 10^10 to 10^(-2), essentially covering the full range of scenarios from the null model containing only the intercept, to the least squares fit.

```{r ridgeInitLambda}
set.seed(1234)
grid=10^seq(10,-2, length =100)
Ridge.Alpha=0
Ridge.Fit = glmnet(X_train, y_train, alpha=Ridge.Alpha, lambda=grid)
Ridge.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.Alpha,nfolds = 10,type.measure = 'deviance')
```

1. Then we use cross validation to choose the optimal lambda for Ridge Regression, as the following:

```{r ridgeOplam}
best.lambda1 = Ridge.Fitcv$lambda.min
best.lambda1
## with crossvaldiation, we get the optimal lambda is equal to 0.0341
plot(Ridge.Fitcv)
```

#### Check Accuarcy

We then need to check accuracy, as assumed before, we would look at whether the predicted data is within $\pm 5\%$. The following is the result.

```{r ridgeAcc}
Ridge.Pred <- predict(Ridge.Fit, s= best.lambda1, newx = X_test)
Ridge.Pred = exp(Ridge.Pred)
accuary = mean(abs(exp(y_test) - (Ridge.Pred))/exp(y_test) <=0.05)
printf("Accuracy of Ridge is approximately %.2f%%", accuracy*100)
```

#### Cross Validation

Then let us take a look at the MSE of this model:

```{r ridgeCV}
sqrt(mean((Ridge.Pred -exp(y_test))^2))
pander(data.frame(R2 = R2(Ridge.Pred,y_test),RMSE = RMSE(Ridge.Pred,y_test),MAE = MAE(Ridge.Pred,y_test)),title="Cross Validation of Ridge Regression")
```

### 5. Lasso Regression

#### Explanation

Lasso regression is pretty similar to Ridge regression. But compare to ridge, Lasso is more interpretable. It will make some predictors' coefficient to be exactly 0, which could help us find out which predictor is what Lasso thinks is important. 

#### Prepare Model

1. Set the initial alpha is equal to 1 (Ridge regression is 0), and also use the same initial lambda, then try to use cross validation to choose the optimal lambda for Lasso.

```{r lassoInitLambda}
Lasso.Alpha=1
grid=10^seq(10,-2, length =100)
set.seed(123)
Lasso.Fit = glmnet(X_train, y_train, alpha=Lasso.Alpha, lambda=grid)
Lasso.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.Alpha,nfolds = 10,type.measure = 'deviance')
```

1. With cross validation, we find out the optimal lambda as following:

```{r lassoOplam}
best.lambda = Lasso.Fitcv$lambda.min
best.lambda
plot(Lasso.Fitcv)
```

#### Coefficient From Lasso Regression

Here we are going to show the predictors lasso choosed.

```{r lassoImp}
lasso.coef = predict(Lasso.Fit, s = best.lambda, type="coefficients")[1:53,]
sort(lasso.coef[lasso.coef!=0],decreasing = TRUE)
```

#### Check Accuarcy

We then need to check accuracy, as assumed before, we would look at whether the predicted data is within the $\pm 5\%$ range. The following is the result.

```{r lassoAcc}
Lasso.Pred =  predict(Lasso.Fit, s= best.lambda, newx = X_test)
Lasso.Pred = exp(Lasso.Pred)
accuary1 = mean(abs(exp(y_test) - Lasso.Pred)/exp(y_test) <=0.05)
printf("Accuracy of Lasso is approximately %.2f%%", accuary1*100)
```

#### Cross Validation

Then let us take a look at the MSE of this model:

```{r lassoCV}
sqrt(mean((Lasso.Pred -exp(y_test))^2))
pander(data.frame(R2 = R2(Lasso.Pred,y_test), RMSE = RMSE(Lasso.Pred,y_test),MAE = MAE(Lasso.Pred,y_test)), title="Cross Validation of Lasso Regression")
```

### 6. Splines (Jingfeng)

#### Cross Validation

### 7. Linear Regression (Yanze)

```{r LRPreparModel1}
lm_model = lm(formula = SalePrice ~.,data = train)
summary(lm_model)
```

```{r LRPreparModel2}
# Multiple R-squared: 0.9475, 
# Adjusted R-squared: 0.9345  
# F-statistic:  73.09  on 289 and 1170 DF, 
# p-value: < 2.2e-16

lm_pred = predict(lm_model, newdata = as.data.frame(test))
#lm_pred  = exp(lm_pred)
#result_lm_model = data.frame(Id = testing_data$Id, SalePrice = lm_pred)
```

#### Cross Validation

### 8. Ensemble

## Classifcation Methods

For classification method, we have separate the values of SalesPrice based on our mean, and we choose to use SVM with different kernels to make the prediction. 

### 1. Support Vector Machine
```{r svmlinear}
library(e1071)
svmfit=svm(SalePrice~., data=train_cl , kernel="linear", cost=10, scale=FALSE)
svmfit
```

```{r svmlinearCV}
tune.out=tune(svm,SalePrice~., data=train_cl,kernel="linear",
ranges=list(cost=c(1,5,10) ))
summary(tune.out)
```

```{r svmpoly}
svmfit=svm(SalePrice~., data=train_cl , kernel="polynomial", cost=10, scale=FALSE)
svmfit
```

```{r svmpolyCV}
tune.out=tune(svm,SalePrice~., data=train_cl,kernel="polynomial",
ranges=list(cost=c(1,5,10) ))
summary(tune.out)
```

```{r svmradial}
svmfit=svm(SalePrice~., data=train_cl , kernel="radial", cost=10, scale=FALSE)
svmfit
```

```{r svmradialCV}
tune.out=tune(svm,SalePrice~., data=train_cl,kernel="radial",
ranges=list(cost=c(1,5,10) ))
summary(tune.out)
```


# Evaluation of different models

Root MSE

# Choose best fit model

# Discussion & Future Development

# Resources






















































