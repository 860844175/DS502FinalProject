---
title: "Homework 1"
author: "Yufei Lin, Jingfeng Xia"
date: "Nov 7 2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
library(pander)
library(knitr)
library(skimr)
library(kableExtra)
library(tinytex)
library(dplyr)
library(purrr)
local({
  hook_inline = knitr::knit_hooks$get('inline')
  knitr::knit_hooks$set(inline = function(x) {
    res = hook_inline(x)
    if (is.numeric(x)) sprintf('$%s$', res) else res
  })
})
```

```{r checkVersion}
# check R version
R.Version()$major
```
```{r libraries, include=FALSE}
library(pander)
library(knitr)
library(skimr)
library(kableExtra)
library(tinytex)
library(dplyr)
library(purrr)
library(pls)
library(randomForest)
library(gam)
library(glmnet)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(caret)
library(mgcv)
library(Metrics)
library(visreg)
```

Variable Name: 
1. HousePricing:1400 dataset
2. train: training data

## Data Processing

### Read in Data

Drop ID!!!!

```{r readData}
vault = read.csv("./SourceData/test.csv")
HousePricing = read.csv("./SourceData/train.csv")
HousePricing = subset(HousePricing,select=-Id)
```

### Pairs of Categories (Iris)

```{r pairsOfCategories}
#pander(summary(HousePricing))
#pairs(HousePricing, main="Pairs plot for the house pricing dataset")
print("Hi")
```

### Feature Engineering

In this section, we convert all missing value based on the following rules:

\begin{enumerate}
\item Categorical: fill in most common
\item Numeric: fill in median/average
\end{enumerate}

Convert all train to HousePricing

```{r fe, include=FALSE}
# remove the irrational data point
ggplot(HousePricing,aes(x=GrLivArea,y=SalePrice))+geom_point()
HousePricing = HousePricing[HousePricing$GrLivArea<4500,]

# find which variables contain NA
NAcol <- which(colSums(is.na(HousePricing)) > 0)
sort(colSums(sapply(HousePricing[NAcol], is.na)), decreasing = TRUE)

# remove NA 
HousePricing$PoolQC[is.na(HousePricing$PoolQC)] = 'None'
quailty = c('None'=0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$PoolQC<-recode(HousePricing$PoolQC,'None'=0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)

HousePricing$MiscFeature[is.na(HousePricing$MiscFeature)] = 'None'
HousePricing$MiscFeature = as.factor(HousePricing$MiscFeature)

HousePricing$Alley[is.na(HousePricing$Alley)] = 'None'
HousePricing$Alley=recode(HousePricing$Alley,'None' = 0,'Pave' = 1,'Grvl' = 2)

HousePricing$Fence[is.na(HousePricing$Fence)] = 'None'
HousePricing$Fence=recode(HousePricing$Fence,'None' = 0,'MnWw' = 1,'GdWo' = 2,'MnPrv' = 3,'GdPrv' = 4)

HousePricing$FireplaceQu[is.na(HousePricing$FireplaceQu)] = 'None'
HousePricing$FireplaceQu=recode(HousePricing$FireplaceQu,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)


HousePricing$LotFrontage[is.na(HousePricing$LotFrontage)]
for (i in 1:nrow(HousePricing)){
  if (is.na(HousePricing$LotFrontage[i])){
    HousePricing$LotFrontage[i] = as.integer(median(HousePricing$LotFrontage[HousePricing$Neighborhood==HousePricing$Neighborhood[i]],na.rm = TRUE))
  }
}


HousePricing$GarageType[is.na(HousePricing$GarageType)] = 'None'
HousePricing$GarageYrBlt[is.na(HousePricing$GarageYrBlt)] <- HousePricing$YearBuilt[is.na(HousePricing$GarageYrBlt)]
HousePricing$GarageFinish[is.na(HousePricing$GarageFinish)] = 'None'
HousePricing$GarageQual[is.na(HousePricing$GarageQual)] = 'None'
HousePricing$GarageCond[is.na(HousePricing$GarageCond)] = 'None'

length(which(is.na(HousePricing$BsmtQual) & is.na(HousePricing$BsmtCond) & is.na(HousePricing$BsmtExposure) & is.na(HousePricing$BsmtFinType1) & is.na(HousePricing$BsmtFinType2)))
HousePricing[!is.na(HousePricing$BsmtFinType1) & (is.na(HousePricing$BsmtCond)|is.na(HousePricing$BsmtQual)|is.na(HousePricing$BsmtExposure)|is.na(HousePricing$BsmtFinType2)), c('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2')]

HousePricing$BsmtFinType2[333] = names(sort(table(HousePricing$BsmtFinType2),decreasing = TRUE))[1]
HousePricing$BsmtExposure[949] = names(sort(table(HousePricing$BsmtExposure),decreasing = TRUE))[1]

HousePricing$BsmtQual[is.na(HousePricing$BsmtQual)] = 'None'
HousePricing$BsmtQual=recode(HousePricing$BsmtQual,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)

HousePricing$BsmtCond[is.na(HousePricing$BsmtCond)] = 'None'
HousePricing$BsmtCond=recode(HousePricing$BsmtCond,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)

HousePricing$BsmtExposure[is.na(HousePricing$BsmtExposure)]='None'
HousePricing$BsmtExposure=recode(HousePricing$BsmtExposure,'None' = 0,'No' = 1,'Mn' = 2,'Av' = 3,'Gd' = 4)

HousePricing$BsmtFinType1[is.na(HousePricing$BsmtFinType1)] = 'None'
HousePricing$BsmtFinType1=recode(HousePricing$BsmtFinType1,'None' = 0,'Unf' = 1,'LwQ' = 2,'Rec' = 3,'BLQ' = 4,'ALQ' = 5,'GLQ' = 6)

HousePricing$BsmtFinType2[is.na(HousePricing$BsmtFinType2)] = 'None'
HousePricing$BsmtFinType2=recode(HousePricing$BsmtFinType2,'None' = 0,'Unf' = 1,'LwQ' = 2,'Rec' = 3,'BLQ' = 4,'ALQ' = 5,'GLQ' = 6)


HousePricing$MasVnrType[is.na(HousePricing$MasVnrType)] = 'None'
median(HousePricing$SalePrice[HousePricing$MasVnrType=='BrkCmn'])
median(HousePricing$SalePrice[HousePricing$MasVnrType=='BrkFace'])
median(HousePricing$SalePrice[HousePricing$MasVnrType=='None'])
median(HousePricing$SalePrice[HousePricing$MasVnrType=='Stone'])
HousePricing$MasVnrType=recode(HousePricing$MasVnrType,'BrkCmn' = 0,'None' = 0,'BrkFace' = 1,'Stone' = 2)

HousePricing$MasVnrArea[(is.na(HousePricing$MasVnrArea))] = 0
HousePricing$Electrical[is.na(HousePricing$Electrical)] <- names(sort(-table(HousePricing$Electrical)))[1]
HousePricing$Electrical=as.factor(HousePricing$Electrical)

HousePricing$MSZoning = as.factor(HousePricing$MSZoning)
HousePricing$Street=recode(HousePricing$Street,'Pave' = 0,'Grvl' = 1)
HousePricing$LotShape=recode(HousePricing$LotShape,'IR3' = 0,'IR2' = 1,'IR1' = 2,'Reg' =2)
HousePricing$Utilities=recode(HousePricing$Utilities,'ELO' = 0,'NoSeWa' = 1,'NoSewr' = 2,'AllPub' =2)
HousePricing$LotConfig = as.factor(HousePricing$LotConfig)
HousePricing$Condition1 = as.factor(HousePricing$Condition1)
HousePricing$Condition2 = as.factor(HousePricing$Condition2)
HousePricing$LandContour = as.factor(HousePricing$LandContour)
HousePricing$RoofStyle = as.factor(HousePricing$RoofStyle)
HousePricing$LandSlope=recode(HousePricing$LandSlope,'Sev' = 0,'Mod' = 1,'Gtl' = 2)
HousePricing$BldgType = as.factor(HousePricing$BldgType)
HousePricing$HouseStyle=as.factor(HousePricing$HouseStyle)
HousePricing$RoofMatl=as.factor(HousePricing$RoofMatl)
HousePricing$Exterior1st=as.factor(HousePricing$Exterior1st)
HousePricing$Exterior2nd=as.factor(HousePricing$Exterior2nd)
HousePricing$ExterQual=recode(HousePricing$ExterQual,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$ExterCond=recode(HousePricing$ExterCond,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$Foundation = as.factor(HousePricing$Foundation)
HousePricing$Heating = as.factor(HousePricing$Heating)
HousePricing$HeatingQC=recode(HousePricing$HeatingQC,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$CentralAir=recode(HousePricing$CentralAir,'N' = 0,'Y' = 1)
HousePricing$KitchenQual=recode(HousePricing$KitchenQua,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$Functional=recode(HousePricing$Functional,'Sal' = 0,'Sev' = 1,'Maj2' = 2,'Maj1' = 3,'Mod' = 4,'Min2' = 5,'Min1' = 6,'Typ' = 7)
HousePricing$GarageType=as.factor(HousePricing$GarageType)

HousePricing$GarageFinish=recode(HousePricing$GarageFinish,'None' = 0,'Unf' = 1,'RFn' = 2,'Fin' = 3)
HousePricing$GarageCond=recode(HousePricing$GarageCond,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)
HousePricing$PavedDrive=recode(HousePricing$PavedDrive,'N' = 0,'P' = 1,'Y' = 2)
HousePricing$SaleType = as.factor(HousePricing$SaleType)
HousePricing$SaleCondition = as.factor(HousePricing$SaleCondition)
HousePricing$MoSold = as.factor(HousePricing$MoSold)
HousePricing$MSSubClass = as.factor(HousePricing$MSSubClass)
```

```{r prepareNewData}
numvar = which(sapply(HousePricing, is.numeric))
catvar = which(sapply(HousePricing, is.factor))
numdata = HousePricing[,numvar]
numcor =(cor(numdata))
corsorted = as.matrix(sort(numcor[,"SalePrice"],decreasing = TRUE))
CorHigh <- names(which(apply(corsorted, 1, function(x) abs(x)>0.5)))
numcor <- numcor[CorHigh, CorHigh]
corrplot.mixed(numcor, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)
temp = subset(HousePricing,select=-SalePrice)
# standardize numerical data 
numeric = select_if(temp,is.numeric)
stnumer = scale(numeric,center = T,scale = T)
convFact = select_if(temp,is.factor)
# one hot
convFact = model.matrix(~.-1,convFact) %>% as.data.frame()
SalePrice = HousePricing$SalePrice
# put standardized numerical data and categorical data in one data?
newdata = cbind(stnumer,convFact,SalePrice)

```

### Boostraping

```{r bootstraping}
set.seed(1234)
sample = sample(dim(newdata)[1],dim(newdata)[1],replace = T)
btnewdata = newdata[sample,]
```


### Seperate into Test and Training Set

Spearate by 70% train, 30% test. 

Convert to CSV upload


```{r separateData}
set.seed(1)
randS = sample(1:nrow(btnewdata), nrow(btnewdata)*0.7)
train = btnewdata[randS,]
test = btnewdata[-randS,]
dim(train)
dim(test)
```
```{r writeToCSV}
#write.csv(train,"./SourceData/train_p.csv", row.names = FALSE)
#write.csv(test,"./SourceData/test_p.csv", row.names = FALSE)
```

```{r newCSVTestTrain}
test = read.csv("./SourceData/test_p.csv")
y_test = test$SalePrice
x_test = subset (test, select = -SalePrice)
train = read.csv("./SourceData/train_p.csv")
y_train = train$SalePrice
x_train = subset (train, select = -SalePrice)
y_train = as.numeric(y_train)
y_test = as.numeric(y_test)
summary(y_train)
```

## Hierachical

Each team member bootstraps training data. 

## Prediction Algorithms

Each model needs a cross validation algorithm
Remember to report RMSE

### 1. PCA (Iris)

```{r PCA}
set.seed(2)
# Need help with PCA analysis
# pcr.fit=pcr(SalePrice~., data=HousePricing, scale=TRUE, validation ="CV")
```

#### Cross Validation

### 2. Random Forest (Yufei Lin)

#### Prepare Model

We have $199$ independent variables in the data set, therefore we have set mtry(Number of randomly selected variables for each split) to be the square root of that number for maximum performance of the model. 

```{r rf-preparemodel}
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train))
rfTrain=randomForest(SalePrice~.,data=train, mtry=sqrt(totalIV)+10,importance =TRUE)
pander(rfTrain)
```

#### Check Accuracy

If we raise the allowance to $\$$10000 We could raise the prediction accuracy to almost 95% of a time.

```{r rfAccuracy}
rfYhat = predict(rfTrain, newdata=x_test)
head(rfYhat)
head(y_test)
#table(y_test, rfYhat)
accuracy = mean(abs(y_test - rfYhat)<=10000)
accuracy
```

Then let us take a look at the MSE of this model: 
```{r rfMSE}
#rfYhat = predict(rfTrain ,newdata=test)
print("The test MSE is shown in the following: ")
mean((rfYhat-test$SalePrice)^2)
```

Here we are going to show the top 10 most important variables in predicting sale price of a house.

```{r rfVarImportance1}
#varImpPlot(rfTrain,n.var=10)
```

```{r rfVarImportance2}
importance = importance(rfTrain)
varImportance = head(data.frame(Variables = row.names(importance),
 Importance =round(importance[, "%IncMSE"],1)),10)
rankImportance=varImportance%>%mutate(Rank=paste('#',dense_rank(desc(Importance))))
ggplot(rankImportance,aes(x=reorder(Variables,Importance),
 y=Importance,fill=Importance))+ 
 geom_bar(stat='identity') + 
 geom_text(aes(x = Variables, y = 0.5, label = Rank),
 hjust=0, vjust=0.55, size = 4, colour = 'white') +
 labs(x = 'Variables') +
 coord_flip() + 
 theme_classic()
```


From the random forest analysis, we have discovered that the top three most important factors for predicting sale price are the following:

\begin{enumerate}
\item OverallQual
\item LotArea
\item GrLivArea
\item Neighbourhood
\end{enumerate}

#### Cross Validation

```{r RFCV2}
set.seed(123) 
  
# computing model performance metrics 
data.frame( R2 = R2(rfYhat, y_test), 
            RMSE = RMSE(rfYhat, y_test), 
            MAE = MAE(rfYhat, y_test)) 
```


Therefore, we will make GAM models according to these three factors. 

### 3. GAM (Yufei Lin)

```{r GAM}
fit1 = gam(SalePrice ~ s(LotFrontage) + s(LotArea) + OverallQual, data = train)
print("Deviance of Model 1")
deviance(fit1)
pred1 = predict(fit1, newdata=x_test)
accuracy = mean(abs(y_test - pred1)<=10000)
print("Accuracy of Model 1")
accuracy
par(mfrow=c(1,2))
plot(fit1 , se=TRUE , col="red")

fit2 = gam(SalePrice ~ OverallCond + s(LotArea) + OverallQual, data = train)
print("Deviance of Model 2")
deviance(fit2)
pred2 = predict(fit2, newdata=x_test)
accuracy = mean(abs(y_test - pred2)<=10000)
print("Accuracy of Model 2")
accuracy
plot(fit2 , se=TRUE , col="red")

fit3 = gam(SalePrice ~ LotFrontage + LandSlope + OverallQual, data = train)
print("Deviance of Model 3")
deviance(fit3)
pred3 = predict(fit3, newdata=x_test)
accuracy = mean(abs(y_test - pred3)<=10000)
print("Accuracy of Model 3")
accuracy
#plot(fit3 , se=TRUE , col="red")
```
```{r GAMSummary}
anova(fit1,fit2,fit3,test="F")
```
From this we know that the deviance is quite large, we need a better model. 

#### Cross Validation

```{r GAMCV}
set.seed(123) 

# computing model performance metrics 
print("Cross Validation of Model 1")
data.frame( R2 = R2(pred1, y_test), 
            RMSE = RMSE(pred1, y_test), 
            MAE = MAE(pred1, y_test))

print("Cross Validation of Model 2")
data.frame( R2 = R2(pred2, y_test), 
            RMSE = RMSE(pred2, y_test), 
            MAE = MAE(pred2, y_test))

print("Cross Validation of Model 3")
data.frame( R2 = R2(pred3, y_test), 
            RMSE = RMSE(pred3, y_test), 
            MAE = MAE(pred3, y_test))
```

### 4. Lasso & Ridge (Jinhong)

```{r LassoRidge}
#LASSO
LassoAlpha=1
LassoLambda = 10^(seq(3,-1,length=100))
set.seed(12)
XTrain = model.matrix(SalePrice~.,data = train1)[,-1]
XTest = model.matrix(SalePrice~.,test1)[,-1]
YTrain = train1$SalePrice
YTest = test1$SalePrice
set.seed(123)
LassoFit = glmnet(XTrain, YTrain, alpha=LassoAlpha, lambda=LassoLambda)
LassoFitcv = cv.glmnet(XTrain, YTrain, alpha = LassoAlpha, lambda = LassoLambda)
bestlambda = LassoFitcv$lambda.min;bestlambda
plot(LassoFitcv)
LassoPred <- predict(LassoFit, s= bestlambda, newx = XTest)
sqrt(mean((LassoPred -YTest)^2))
predict(LassoFit, s = bestlambda, type="coefficients")
```

#### Cross Validation

### 5. Splines (Jingfeng)

#### Cross Validation

### 6. Linear Regression (Yanze)

```{r LRPreparModel1}
lm_model = lm(formula = SalePrice ~.,data = train)

summary(lm_model)
```

```{r LRPreparModel2}
# Multiple R-squared: 0.9475, 
# Adjusted R-squared: 0.9345  
# F-statistic:  73.09  on 289 and 1170 DF, 
# p-value: < 2.2e-16

lm_pred = predict(lm_model, newdata = as.data.frame(test))
lm_pred  = exp(lm_pred)
lm_pred
#result_lm_model = data.frame(Id = testing_data$Id, SalePrice = lm_pred)
```

#### Cross Validation

### 7. Ensemble

## Evaluation of different models

Root MSE

## Choose best fit model

## Discussion & Future Development

## Resources
https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda































































